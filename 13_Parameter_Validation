name: Parameter Validation Component (FIXED)
description: Validates and optimizes clustering algorithm parameters before training. Provides data-driven parameter recommendations, validates parameter constraints, and ensures optimal configuration for clustering quality. FIXED to handle various JSON input formats from Elyra.

inputs:
  - name: train_data
    type: Data
    description: 'Preprocessed training dataset (CSV)'
  - name: distance_statistics
    type: Data
    description: 'Distance statistics from validation (JSON)'
  - name: algorithm
    type: String
    description: 'Clustering algorithm: kmeans, dbscan, hierarchical, gmm, spectral, optics, meanshift, birch'
    default: 'kmeans'
  - name: proposed_params
    type: String
    description: 'Proposed algorithm parameters as JSON to validate and optimize. Can be JSON string or dict-like string.'
    default: '{}'

outputs:
  - name: validated_params
    type: Data
    description: 'Validated and optimized parameters (JSON)'
  - name: parameter_report
    type: Data
    description: 'Parameter validation report with recommendations (JSON)'

implementation:
  container:
    image: nikhilv215/nesy-factory:v23
    command:
      - python3
      - -u
      - -c
      - |
        import os
        import sys
        import json
        import argparse
        import logging
        import pandas as pd
        import numpy as np
        from pathlib import Path
        import math
        import ast
        
        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
        logger = logging.getLogger('parameter_validation')
        
        PARAMETER_CONSTRAINTS = {
            'kmeans': {
                'n_clusters': {
                    'type': int,
                    'min': 2,
                    'max_rule': 'sqrt(n/2)',
                    'recommended_rule': 'elbow_method',
                    'description': 'Number of clusters'
                },
                'init': {
                    'type': str,
                    'options': ['k-means++', 'random'],
                    'default': 'k-means++',
                    'description': 'Initialization method'
                },
                'n_init': {
                    'type': int,
                    'min': 1,
                    'max': 100,
                    'default': 10,
                    'description': 'Number of initializations'
                },
                'max_iter': {
                    'type': int,
                    'min': 100,
                    'max': 10000,
                    'default': 300,
                    'description': 'Maximum iterations'
                }
            },
            'dbscan': {
                'eps': {
                    'type': float,
                    'min': 0.0,
                    'recommended_rule': 'knn_distance',
                    'description': 'Neighborhood radius'
                },
                'min_samples': {
                    'type': int,
                    'min': 2,
                    'recommended_rule': '2*n_features',
                    'default': 5,
                    'description': 'Minimum points in neighborhood'
                },
                'metric': {
                    'type': str,
                    'options': ['euclidean', 'manhattan', 'chebyshev', 'minkowski'],
                    'default': 'euclidean',
                    'description': 'Distance metric'
                }
            },
            'hierarchical': {
                'n_clusters': {
                    'type': int,
                    'min': 2,
                    'max_rule': 'sqrt(n/2)',
                    'description': 'Number of clusters (if not using distance_threshold)'
                },
                'linkage': {
                    'type': str,
                    'options': ['ward', 'complete', 'average', 'single'],
                    'default': 'ward',
                    'description': 'Linkage criterion'
                },
                'distance_threshold': {
                    'type': float,
                    'min': 0.0,
                    'description': 'Distance threshold for forming flat clusters'
                }
            },
            'gmm': {
                'n_components': {
                    'type': int,
                    'min': 2,
                    'max_rule': 'sqrt(n/2)',
                    'recommended_rule': 'bic_aic',
                    'description': 'Number of mixture components'
                },
                'covariance_type': {
                    'type': str,
                    'options': ['full', 'tied', 'diag', 'spherical'],
                    'default': 'full',
                    'description': 'Covariance matrix type'
                },
                'max_iter': {
                    'type': int,
                    'min': 100,
                    'max': 10000,
                    'default': 100,
                    'description': 'Maximum EM iterations'
                }
            },
            'spectral': {
                'n_clusters': {
                    'type': int,
                    'min': 2,
                    'max_rule': 'sqrt(n/2)',
                    'description': 'Number of clusters'
                },
                'affinity': {
                    'type': str,
                    'options': ['nearest_neighbors', 'rbf', 'precomputed'],
                    'default': 'rbf',
                    'description': 'Kernel type for affinity matrix'
                },
                'n_neighbors': {
                    'type': int,
                    'min': 2,
                    'default': 10,
                    'description': 'Number of neighbors (if using nearest_neighbors)'
                }
            },
            'optics': {
                'min_samples': {
                    'type': int,
                    'min': 2,
                    'recommended_rule': '2*n_features',
                    'default': 5,
                    'description': 'Minimum points in neighborhood'
                },
                'max_eps': {
                    'type': float,
                    'min': 0.0,
                    'description': 'Maximum epsilon neighborhood'
                },
                'metric': {
                    'type': str,
                    'options': ['euclidean', 'manhattan', 'chebyshev', 'minkowski'],
                    'default': 'euclidean',
                    'description': 'Distance metric'
                }
            },
            'meanshift': {
                'bandwidth': {
                    'type': float,
                    'min': 0.0,
                    'recommended_rule': 'estimate_bandwidth',
                    'description': 'Kernel bandwidth'
                },
                'bin_seeding': {
                    'type': bool,
                    'default': False,
                    'description': 'Use discretized binning for seeding'
                }
            },
            'birch': {
                'n_clusters': {
                    'type': int,
                    'min': 2,
                    'max_rule': 'sqrt(n/2)',
                    'description': 'Number of clusters after hierarchical clustering'
                },
                'threshold': {
                    'type': float,
                    'min': 0.0,
                    'default': 0.5,
                    'description': 'Radius of subcluster'
                },
                'branching_factor': {
                    'type': int,
                    'min': 2,
                    'default': 50,
                    'description': 'Maximum CF subclusters in each node'
                }
            }
        }
        
        def ensure_directory_exists(filepath):
            Path(filepath).parent.mkdir(parents=True, exist_ok=True)
        
        def load_data(filepath):
            logger.info("Loading data from: " + filepath)
            return pd.read_csv(filepath)
        
        def load_json(filepath):
            logger.info("Loading JSON from: " + filepath)
            with open(filepath, 'r') as f:
                return json.load(f)
        
        def parse_proposed_params(param_string):
            #Robust parsing of proposed parameters from various input formats.
            #Handles: JSON strings, Python dict strings, escaped JSON, malformed inputs.
            logger.info("Raw proposed_params input:")
            logger.info("  Type: " + str(type(param_string)))
            logger.info("  Value: " + repr(param_string))
            
            if not param_string or param_string.strip() == '':
                logger.info("Empty parameters, using default {}")
                return {}
            
            # Try Method 1: Standard JSON parsing
            try:
                params = json.loads(param_string)
                logger.info("âœ“ Parsed via json.loads()")
                return params
            except json.JSONDecodeError as e:
                logger.info("Method 1 failed (json.loads): " + str(e))
            
            # Try Method 2: Python literal_eval (handles {'key': value} format)
            try:
                params = ast.literal_eval(param_string)
                if isinstance(params, dict):
                    logger.info("âœ“ Parsed via ast.literal_eval()")
                    return params
            except (ValueError, SyntaxError) as e:
                logger.info("Method 2 failed (literal_eval): " + str(e))
            
            # Try Method 3: Remove escaping and try again
            try:
                cleaned = param_string.replace('\\"', '"').replace("\\'", "'")
                params = json.loads(cleaned)
                logger.info("âœ“ Parsed after removing escapes")
                return params
            except json.JSONDecodeError as e:
                logger.info("Method 3 failed (cleaned json): " + str(e))
            
            # Try Method 4: Single quotes to double quotes conversion
            try:
                converted = param_string.replace("'", '"')
                params = json.loads(converted)
                logger.info("âœ“ Parsed after quote conversion")
                return params
            except json.JSONDecodeError as e:
                logger.info("Method 4 failed (quote conversion): " + str(e))
            
            # Try Method 5: Manual key-value extraction for simple cases
            try:
                import re
                if 'n_clusters' in param_string:
                    match = re.search(r'n_clusters["\s:]+(\d+)', param_string)
                    if match:
                        n_clusters = int(match.group(1))
                        params = {'n_clusters': n_clusters}
                        logger.info("âœ“ Extracted n_clusters manually: " + str(n_clusters))
                        return params
            except Exception as e:
                logger.info("Method 5 failed (manual extraction): " + str(e))
            
            # All methods failed
            logger.error("ERROR: Could not parse proposed_params from any method")
            logger.error("Please ensure input is valid JSON like: {\"n_clusters\": 3}")
            logger.error("Or valid Python dict like: {'n_clusters': 3}")
            sys.exit(1)
        
        def calculate_optimal_parameters(algorithm, train_df, distance_stats):
            logger.info("")
            logger.info("Calculating optimal parameters based on data characteristics")
            
            n_samples = len(train_df)
            n_features = len(train_df.columns)
            
            optimal_params = {}
            
            if algorithm == 'kmeans':
                max_k = int(math.sqrt(n_samples / 2))
                elbow_k = min(max(3, int(math.sqrt(n_samples / 10))), max_k)
                
                optimal_params['n_clusters'] = {
                    'calculated': elbow_k,
                    'reasoning': "Elbow method heuristic: sqrt(n/10), capped at sqrt(n/2)"
                }
                optimal_params['init'] = {
                    'calculated': 'k-means++',
                    'reasoning': 'Best practice for initialization'
                }
                optimal_params['n_init'] = {
                    'calculated': 10,
                    'reasoning': 'Standard number of initializations'
                }
                
            elif algorithm == 'dbscan':
                mean_knn_dist = distance_stats.get('mean_distance', 1.0)
                optimal_eps = mean_knn_dist * 1.5
                optimal_min_samples = max(2, min(2 * n_features, 10))
                
                optimal_params['eps'] = {
                    'calculated': round(optimal_eps, 4),
                    'reasoning': "1.5x mean k-NN distance"
                }
                optimal_params['min_samples'] = {
                    'calculated': optimal_min_samples,
                    'reasoning': "2 * n_features, capped at 10"
                }
                
            elif algorithm == 'hierarchical':
                max_k = int(math.sqrt(n_samples / 2))
                optimal_k = min(max(3, int(math.sqrt(n_samples / 10))), max_k)
                
                optimal_params['n_clusters'] = {
                    'calculated': optimal_k,
                    'reasoning': "Similar to k-means heuristic"
                }
                optimal_params['linkage'] = {
                    'calculated': 'ward',
                    'reasoning': "Best for compact clusters with Euclidean distance"
                }
                
            elif algorithm == 'gmm':
                max_k = int(math.sqrt(n_samples / 2))
                optimal_k = min(max(2, int(math.sqrt(n_samples / 10))), max_k)
                
                optimal_params['n_components'] = {
                    'calculated': optimal_k,
                    'reasoning': "Based on sample size heuristic"
                }
                optimal_params['covariance_type'] = {
                    'calculated': 'full',
                    'reasoning': "Most flexible, suitable for general data"
                }
                
            elif algorithm == 'spectral':
                max_k = int(math.sqrt(n_samples / 2))
                optimal_k = min(max(2, int(math.sqrt(n_samples / 10))), max_k)
                
                optimal_params['n_clusters'] = {
                    'calculated': optimal_k,
                    'reasoning': "Based on sample size"
                }
                optimal_params['affinity'] = {
                    'calculated': 'rbf',
                    'reasoning': "Good default for non-linear boundaries"
                }
                
            elif algorithm == 'optics':
                optimal_min_samples = max(2, min(2 * n_features, 10))
                
                optimal_params['min_samples'] = {
                    'calculated': optimal_min_samples,
                    'reasoning': "2 * n_features"
                }
                
            elif algorithm == 'meanshift':
                mean_dist = distance_stats.get('mean_distance', 1.0)
                optimal_bandwidth = mean_dist * 2.0
                
                optimal_params['bandwidth'] = {
                    'calculated': round(optimal_bandwidth, 4),
                    'reasoning': "2x mean distance for appropriate kernel width"
                }
                
            elif algorithm == 'birch':
                max_k = int(math.sqrt(n_samples / 2))
                optimal_k = min(max(2, int(math.sqrt(n_samples / 10))), max_k)
                
                optimal_params['n_clusters'] = {
                    'calculated': optimal_k,
                    'reasoning': "Based on sample size"
                }
                optimal_params['threshold'] = {
                    'calculated': 0.5,
                    'reasoning': "Default threshold for subcluster radius"
                }
            
            return optimal_params
        
        def validate_parameters(algorithm, proposed_params, optimal_params, constraints):
            logger.info("")
            logger.info("Validating proposed parameters")
            
            validated_params = {}
            warnings = []
            recommendations = []
            
            for param_name, constraint in constraints.items():
                logger.info("  " + param_name + ":")
                
                if param_name in proposed_params:
                    value = proposed_params[param_name]
                    logger.info("    Proposed: " + str(value))
                    
                    expected_type = constraint['type']
                    if not isinstance(value, expected_type):
                        try:
                            value = expected_type(value)
                            warnings.append("Converted " + param_name + " to " + str(expected_type.__name__))
                        except:
                            warnings.append("Invalid type for " + param_name + ", using optimal")
                            value = optimal_params.get(param_name, {}).get('calculated')
                    
                    if 'options' in constraint and value not in constraint['options']:
                        warnings.append(param_name + " value " + str(value) + " not in " + str(constraint['options']))
                        value = constraint.get('default', constraint['options'][0])
                    
                    if 'min' in constraint and value < constraint['min']:
                        warnings.append(param_name + " below minimum, adjusting")
                        value = constraint['min']
                    
                    validated_params[param_name] = value
                    
                    if param_name in optimal_params:
                        optimal_value = optimal_params[param_name]['calculated']
                        if value != optimal_value:
                            recommendations.append(
                                param_name + ": Proposed=" + str(value) + 
                                ", Optimal=" + str(optimal_value) + 
                                " (" + optimal_params[param_name]['reasoning'] + ")"
                            )
                    
                    logger.info("    âœ“ Validated: " + str(value))
                    
                elif param_name in optimal_params:
                    value = optimal_params[param_name]['calculated']
                    validated_params[param_name] = value
                    warnings.append("Missing " + param_name + ", using optimal: " + str(value))
                    logger.info("    Using optimal: " + str(value))
                    
                elif 'default' in constraint:
                    value = constraint['default']
                    validated_params[param_name] = value
                    logger.info("    Using default: " + str(value))
            
            return validated_params, warnings, recommendations
        
        def main():
            parser = argparse.ArgumentParser()
            parser.add_argument("--train_data", required=True)
            parser.add_argument("--distance_statistics", required=True)
            parser.add_argument("--algorithm", default='kmeans')
            parser.add_argument("--proposed_params", default='{}')
            parser.add_argument("--output_validated_params", required=True)
            parser.add_argument("--output_parameter_report", required=True)
            
            args = parser.parse_args()
            
            logger.info("="*80)
            logger.info("PARAMETER VALIDATION & OPTIMIZATION")
            logger.info("="*80)
            logger.info("Algorithm: " + args.algorithm)
            logger.info("")
            
            try:
                ensure_directory_exists(args.output_validated_params)
                ensure_directory_exists(args.output_parameter_report)
                
                # FIXED: Use robust parsing
                proposed_params = parse_proposed_params(args.proposed_params)
                logger.info("Successfully parsed parameters: " + str(proposed_params))
                logger.info("")
                
                train_df = load_data(args.train_data)
                distance_stats = load_json(args.distance_statistics)
                
                if args.algorithm not in PARAMETER_CONSTRAINTS:
                    logger.error("ERROR: Unsupported algorithm: " + args.algorithm)
                    sys.exit(1)
                
                constraints = PARAMETER_CONSTRAINTS[args.algorithm]
                
                optimal_params = calculate_optimal_parameters(
                    args.algorithm,
                    train_df,
                    distance_stats
                )
                
                logger.info("")
                logger.info("Optimal parameters calculated:")
                for param, info in optimal_params.items():
                    logger.info("  " + param + ": " + str(info['calculated']) + 
                               " (" + info['reasoning'] + ")")
                
                validated_params, warnings, recommendations = validate_parameters(
                    args.algorithm,
                    proposed_params,
                    optimal_params,
                    constraints
                )
                
                parameter_report = {
                    'algorithm': args.algorithm,
                    'proposed_params': proposed_params,
                    'validated_params': validated_params,
                    'optimal_params': {k: v['calculated'] for k, v in optimal_params.items()},
                    'warnings': warnings,
                    'recommendations': recommendations,
                    'data_characteristics': {
                        'n_samples': len(train_df),
                        'n_features': len(train_df.columns),
                        'distance_statistics': distance_stats
                    }
                }
                
                logger.info("")
                logger.info("="*80)
                logger.info("VALIDATION SUMMARY")
                logger.info("="*80)
                logger.info("âœ“ Validated parameters: " + str(validated_params))
                
                if warnings:
                    logger.info("")
                    logger.info("âš  Warnings:")
                    for warning in warnings:
                        logger.info("  - " + warning)
                
                if recommendations:
                    logger.info("")
                    logger.info("ðŸ’¡ Recommendations:")
                    for rec in recommendations:
                        logger.info("  - " + rec)
                
                with open(args.output_validated_params, 'w') as f:
                    json.dump(validated_params, f, indent=2)
                
                with open(args.output_parameter_report, 'w') as f:
                    json.dump(parameter_report, f, indent=2)
                
                logger.info("")
                logger.info("âœ“ Parameter validation complete!")
                logger.info("="*80)
                
            except Exception as e:
                logger.error("ERROR: " + str(e))
                import traceback
                traceback.print_exc()
                sys.exit(1)
        
        if __name__ == "__main__":
            main()
      - --train_data
      - {inputPath: train_data}
      - --distance_statistics
      - {inputPath: distance_statistics}
      - --algorithm
      - {inputValue: algorithm}
      - --proposed_params
      - {inputValue: proposed_params}
      - --output_validated_params
      - {outputPath: validated_params}
      - --output_parameter_report
      - {outputPath: parameter_report}
