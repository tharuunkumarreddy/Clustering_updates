name: Generic Distance Matrix Validation Component - All ML Algorithms
description: Validates distance matrix properties for clustering and distance-based algorithms. For supervised tree/linear models that do not use distance metrics, skips validation and outputs a compatibility report. Supports all clustering algorithms + KNN, SVM, MLP. Loads Parquet/CSV.

inputs:
  - name: train_data
    type: Data
    description: 'Preprocessed training dataset (Parquet or CSV)'
  - name: test_data
    type: Data
    description: 'Preprocessed test dataset (Parquet or CSV, optional)'
  - name: validation_params
    type: String
    description: 'Validation parameters as JSON. Examples: {"sample_size":1000}, {"distance_metrics":["euclidean","manhattan"]}'
    default: '{}'
  - name: task_type
    type: String
    description: 'Task type: "clustering" or "supervised". For supervised tree/linear models, distance validation is skipped.'
    default: 'clustering'
  - name: algorithm
    type: String
    description: 'Target algorithm name (e.g. KMeans, RandomForestClassifier). Used to determine if distance validation is needed.'
    default: 'KMeans'

outputs:
  - name: validation_report
    type: Data
    description: 'Distance matrix validation report with recommendations (JSON)'
  - name: distance_statistics
    type: Data
    description: 'Distance distribution statistics (JSON)'

implementation:
  container:
    image: nikhilv215/nesy-factory:v23
    command:
      - python3
      - -u
      - -c
      - |
        import os
        import sys
        import json
        import argparse
        import logging
        import pandas as pd
        import numpy as np
        from scipy.spatial.distance import pdist, squareform, cdist
        from scipy.stats import ks_2samp
        from sklearn.metrics import pairwise_distances
        from pathlib import Path
        
        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
        logger = logging.getLogger('distance_validation')

        # Algorithm-Distance Metric Compatibility Database (PRESERVED IN FULL)
        ALGORITHM_DISTANCE_PREFERENCES = {
            # Centroid-Based
            'KMeans': {
                'recommended': ['euclidean', 'minkowski'],
                'avoid': ['cosine'],
                'reason': 'KMeans uses Euclidean distance for centroid calculation and convergence.'
            },
            'MiniBatchKMeans': {
                'recommended': ['euclidean', 'minkowski'],
                'avoid': ['cosine'],
                'reason': 'Same as KMeans - Euclidean distance for efficient batch processing.'
            },
            'BisectingKMeans': {
                'recommended': ['euclidean', 'minkowski'],
                'avoid': ['cosine'],
                'reason': 'Hierarchical K-means using Euclidean distance for splits.'
            },
            'KMedoids': {
                'recommended': ['euclidean', 'manhattan', 'cosine'],
                'avoid': [],
                'reason': 'K-medoids works with any distance metric - very flexible.'
            },
            
            # Density-Based
            'DBSCAN': {
                'recommended': ['euclidean', 'manhattan', 'chebyshev'],
                'avoid': ['cosine'],
                'reason': 'DBSCAN needs metric space properties for epsilon-neighborhood density calculation.'
            },
            'OPTICS': {
                'recommended': ['euclidean', 'manhattan'],
                'avoid': ['cosine'],
                'reason': 'OPTICS requires metric space for reachability distance computation.'
            },
            'HDBSCAN': {
                'recommended': ['euclidean', 'manhattan'],
                'avoid': ['cosine'],
                'reason': 'Hierarchical density clustering needs metric space for mutual reachability.'
            },
            
            # Hierarchical
            'AgglomerativeClustering': {
                'recommended': ['euclidean', 'manhattan', 'cosine', 'correlation'],
                'avoid': [],
                'reason': 'Hierarchical clustering works with any distance metric based on linkage.'
            },
            'BIRCH': {
                'recommended': ['euclidean'],
                'avoid': ['manhattan', 'cosine'],
                'reason': 'BIRCH uses Euclidean distance for clustering feature tree construction.'
            },
            
            # Distribution-Based
            'GaussianMixture': {
                'recommended': ['euclidean'],
                'avoid': [],
                'reason': 'GMM uses Mahalanobis distance internally for Gaussian likelihood.'
            },
            'BayesianGaussianMixture': {
                'recommended': ['euclidean'],
                'avoid': [],
                'reason': 'Bayesian GMM uses probabilistic distances based on Gaussian assumptions.'
            },
            
            # Fuzzy
            'FuzzyCMeans': {
                'recommended': ['euclidean', 'manhattan'],
                'avoid': [],
                'reason': 'Fuzzy C-Means uses distance for membership degree calculation.'
            },
            
            # Other
            'MeanShift': {
                'recommended': ['euclidean'],
                'avoid': ['manhattan', 'cosine'],
                'reason': 'Mean Shift uses Euclidean distance for kernel density estimation.'
            },
            'AffinityPropagation': {
                'recommended': ['euclidean', 'manhattan'],
                'avoid': [],
                'reason': 'Affinity Propagation uses negative squared distance for similarity matrix.'
            },
            'SpectralClustering': {
                'recommended': ['rbf', 'euclidean'],
                'avoid': ['manhattan', 'chebyshev'],
                'reason': 'Spectral uses RBF kernel or Euclidean for similarity/affinity matrix.'
            },
            # -- SUPERVISED: Distance-based (validation IS relevant) --------------------
            'KNeighborsClassifier': {
                'recommended': ['euclidean', 'manhattan', 'minkowski'],
                'avoid': [],
                'reason': 'KNN uses distances directly for neighbor lookup. Distance metric choice is critical.'
            },
            'KNeighborsRegressor': {
                'recommended': ['euclidean', 'manhattan', 'minkowski'],
                'avoid': [],
                'reason': 'KNN uses distances directly. Metric choice significantly affects predictions.'
            },
            'SVC': {
                'recommended': ['euclidean'],
                'avoid': [],
                'reason': 'SVM with RBF kernel implicitly uses Euclidean distance for kernel computation.'
            },
            'SVR': {
                'recommended': ['euclidean'],
                'avoid': [],
                'reason': 'SVR with RBF kernel implicitly uses Euclidean distance.'
            },
            # -- SUPERVISED: Distance-irrelevant (validation SKIPPED) ------------------
            'RandomForestClassifier': {'recommended': ['N/A'], 'avoid': [], 'reason': 'Tree-based: distance-invariant. Validation skipped.'},
            'RandomForestRegressor': {'recommended': ['N/A'], 'avoid': [], 'reason': 'Tree-based: distance-invariant. Validation skipped.'},
            'GradientBoostingClassifier': {'recommended': ['N/A'], 'avoid': [], 'reason': 'Boosted trees: distance-invariant. Validation skipped.'},
            'GradientBoostingRegressor': {'recommended': ['N/A'], 'avoid': [], 'reason': 'Boosted trees: distance-invariant. Validation skipped.'},
            'XGBClassifier': {'recommended': ['N/A'], 'avoid': [], 'reason': 'XGBoost: distance-invariant. Validation skipped.'},
            'XGBRegressor': {'recommended': ['N/A'], 'avoid': [], 'reason': 'XGBoost: distance-invariant. Validation skipped.'},
            'LGBMClassifier': {'recommended': ['N/A'], 'avoid': [], 'reason': 'LightGBM: distance-invariant. Validation skipped.'},
            'LGBMRegressor': {'recommended': ['N/A'], 'avoid': [], 'reason': 'LightGBM: distance-invariant. Validation skipped.'},
            'AdaBoostClassifier': {'recommended': ['N/A'], 'avoid': [], 'reason': 'AdaBoost: distance-invariant. Validation skipped.'},
            'AdaBoostRegressor': {'recommended': ['N/A'], 'avoid': [], 'reason': 'AdaBoost: distance-invariant. Validation skipped.'},
            'DecisionTreeClassifier': {'recommended': ['N/A'], 'avoid': [], 'reason': 'Decision tree: distance-invariant. Validation skipped.'},
            'DecisionTreeRegressor': {'recommended': ['N/A'], 'avoid': [], 'reason': 'Decision tree: distance-invariant. Validation skipped.'},
            'LogisticRegression': {'recommended': ['N/A'], 'avoid': [], 'reason': 'Linear model: distance-invariant. Validation skipped.'},
            'LinearRegression': {'recommended': ['N/A'], 'avoid': [], 'reason': 'Linear model: distance-invariant. Validation skipped.'},
            'Ridge': {'recommended': ['N/A'], 'avoid': [], 'reason': 'Linear model: distance-invariant. Validation skipped.'},
            'Lasso': {'recommended': ['N/A'], 'avoid': [], 'reason': 'Linear model: distance-invariant. Validation skipped.'},
            'ElasticNet': {'recommended': ['N/A'], 'avoid': [], 'reason': 'Linear model: distance-invariant. Validation skipped.'},
            'MLPClassifier': {'recommended': ['N/A'], 'avoid': [], 'reason': 'MLP: distance-invariant. Validation skipped.'},
            'MLPRegressor': {'recommended': ['N/A'], 'avoid': [], 'reason': 'MLP: distance-invariant. Validation skipped.'},
            'GaussianNB': {'recommended': ['N/A'], 'avoid': [], 'reason': 'Naive Bayes: distance-invariant. Validation skipped.'}
        }

        # Algorithms that do NOT use distance metrics -" skip full validation
        DISTANCE_IRRELEVANT_ALGOS = {
            'RandomForestClassifier', 'RandomForestRegressor',
            'GradientBoostingClassifier', 'GradientBoostingRegressor',
            'XGBClassifier', 'XGBRegressor',
            'LGBMClassifier', 'LGBMRegressor',
            'AdaBoostClassifier', 'AdaBoostRegressor',
            'DecisionTreeClassifier', 'DecisionTreeRegressor',
            'LogisticRegression', 'LinearRegression',
            'Ridge', 'Lasso', 'ElasticNet',
            'MLPClassifier', 'MLPRegressor',
            'GaussianNB'
        }
        
        def ensure_directory_exists(file_path):
            #Ensure directory exists for output file#
            directory = os.path.dirname(file_path)
            if directory:
                os.makedirs(directory, exist_ok=True)
        
        def detect_file_type(file_path):
            # Detect file type by MAGIC BYTES first (not extension).
            # CRITICAL FIX: Kubernetes passes files without extensions
            try:
                with open(file_path, 'rb') as f:
                    header = f.read(8)
                if header[:4] == b'PAR1':
                    logger.info("[OK] Detected: Parquet (PAR1 magic bytes)")
                    return 'parquet'
                if header[1:6] == b'NUMPY':
                    logger.info("[OK] Detected: NumPy array")
                    return 'numpy'
                if header[:2] in [b'PK', b'\x80\x04']:
                    logger.info("[OK] Detected: Pickle/ZIP")
                    return 'pickle'
                try:
                    text_start = open(file_path, 'r', errors='replace').read(512)
                    if text_start.strip().startswith('{') or text_start.strip().startswith('['):
                        return 'json'
                    return 'csv'
                except Exception:
                    return 'csv'
            except Exception as e:
                logger.warning("Magic byte detection failed: " + str(e) + ", defaulting to CSV")
                return 'csv'

        def load_data(input_path):
            # Load data with MAGIC BYTES detection first.
            # CRITICAL FIX: Kubernetes strips file extensions.
            if not input_path or input_path == '':
                return None
            logger.info("Loading dataset from: " + input_path)
            ext = Path(input_path).suffix.lower()
            logger.info("File extension: '" + ext + "' (may be empty on Kubernetes)")
            detected_type = detect_file_type(input_path)
            try:
                if ext in ['.parquet', '.pq'] or detected_type == 'parquet':
                    logger.info("Loading as Parquet...")
                    df = pd.read_parquet(input_path, engine='pyarrow')
                    logger.info("[OK] Loaded Parquet: " + str(df.shape[0]) + " rows x " + str(df.shape[1]) + " columns")
                    return df
                logger.info("Loading as CSV...")
                for enc in ['utf-8', 'latin-1', 'cp1252']:
                    try:
                        df = pd.read_csv(input_path, encoding=enc)
                        logger.info("[OK] Loaded CSV (" + enc + "): " + str(df.shape[0]) + " rows x " + str(df.shape[1]) + " columns")
                        return df
                    except UnicodeDecodeError:
                        continue
                raise ValueError("Could not decode file with any supported encoding")
            except Exception as e:
                logger.error("Error loading data: " + str(e))
                raise
        
        def validate_distance_matrix(X, metric='euclidean', sample_size=None, params=None):
            #Validate distance matrix properties
            #Checks: symmetry, triangle inequality, zero diagonal, distance distribution
            if params is None:
                params = {}
            logger.info("Validating distance matrix properties")
            logger.info(f"  Metric: {metric}")
            logger.info(f"  Data shape: {X.shape}")
            
            # Sample if needed
            if sample_size and len(X) > sample_size:
                logger.info(f"  Sampling {sample_size} points for validation")
                indices = np.random.choice(len(X), sample_size, replace=False)
                X_sample = X[indices]
            else:
                X_sample = X
            
            validation_results = {
                'metric': metric,
                'n_samples': len(X_sample),
                'n_features': X.shape[1]
            }
            
            try:
                # Compute pairwise distances
                distances = pdist(X_sample, metric=metric)
                dist_matrix = squareform(distances)
                
                validation_results['distance_computed'] = True
                
                # Distance statistics
                validation_results['distance_stats'] = {
                    'min': float(np.min(distances)),
                    'max': float(np.max(distances)),
                    'mean': float(np.mean(distances)),
                    'median': float(np.median(distances)),
                    'std': float(np.std(distances)),
                    'q25': float(np.percentile(distances, 25)),
                    'q75': float(np.percentile(distances, 75))
                }
                
                logger.info(f"  Distance range: {validation_results['distance_stats']['min']:.4f} " +
                           f"to {validation_results['distance_stats']['max']:.4f}")
                logger.info(f"  Distance mean: {validation_results['distance_stats']['mean']:.4f}")
                
                # Check symmetry
                is_symmetric = np.allclose(dist_matrix, dist_matrix.T)
                validation_results['is_symmetric'] = bool(is_symmetric)
                
                # Check diagonal is zero
                diagonal_zero = np.allclose(np.diag(dist_matrix), 0)
                validation_results['diagonal_is_zero'] = bool(diagonal_zero)
                
                # Check triangle inequality only for small samples.
                # Configurable via validation_params['triangle_check_max'] (default 100).
                _tri_max = params.get('triangle_check_max', 100)
                if len(X_sample) <= _tri_max:
                    triangle_violations = 0
                    for i in range(len(dist_matrix)):
                        for j in range(i+1, len(dist_matrix)):
                            for k in range(j+1, len(dist_matrix)):
                                if dist_matrix[i,j] > dist_matrix[i,k] + dist_matrix[k,j] + 1e-10:
                                    triangle_violations += 1
                    
                    validation_results['triangle_inequality_violations'] = int(triangle_violations)
                    validation_results['triangle_inequality_satisfied'] = bool(triangle_violations == 0)
                    logger.info(f"  Triangle inequality violations: {triangle_violations}")
                else:
                    validation_results['triangle_inequality_check'] = 'skipped (too many samples)'
                
                # Check for zero distances (duplicates)
                zero_distances = np.sum(distances == 0)
                validation_results['n_zero_distances'] = int(zero_distances)
                validation_results['pct_zero_distances'] = float(zero_distances / len(distances) * 100)
                
                _zero_warn = params.get('zero_dist_warn_pct', 5.0)
                if validation_results['pct_zero_distances'] > _zero_warn:
                    logger.warning(f"  s  Warning: {validation_results['pct_zero_distances']:.2f}% " +
                                 f"of distances are zero (possible duplicates)")
                
                # Nearest neighbor statistics
                nearest_neighbor_dists = np.partition(
                    dist_matrix + np.eye(len(dist_matrix))*1e10, 1, axis=1
                )[:,1]
                validation_results['nearest_neighbor_stats'] = {
                    'min': float(np.min(nearest_neighbor_dists)),
                    'max': float(np.max(nearest_neighbor_dists)),
                    'mean': float(np.mean(nearest_neighbor_dists)),
                    'median': float(np.median(nearest_neighbor_dists))
                }
                
                logger.info(f"  Nearest neighbor distance (mean): " +
                           f"{validation_results['nearest_neighbor_stats']['mean']:.4f}")
                
            except Exception as e:
                logger.error(f"  Failed to compute distance matrix: {str(e)}")
                validation_results['distance_computed'] = False
                validation_results['error'] = str(e)
            
            return validation_results, distances if 'distances' in locals() else None
        
        def analyze_data_characteristics(X):
            #Analyze data characteristics for algorithm recommendations#
            logger.info("Analyzing data characteristics")
            
            characteristics = {
                'n_samples': X.shape[0],
                'n_features': X.shape[1],
                'feature_stats': {}
            }
            
            # Feature scale analysis
            feature_means = np.mean(X, axis=0)
            feature_stds = np.std(X, axis=0)
            
            characteristics['feature_stats']['mean_range'] = [
                float(np.min(feature_means)), 
                float(np.max(feature_means))
            ]
            characteristics['feature_stats']['std_range'] = [
                float(np.min(feature_stds)), 
                float(np.max(feature_stds))
            ]
            
            # Check scaling uniformity
            std_uniformity = np.std(feature_stds) / (np.mean(feature_stds) + 1e-10)
            characteristics['feature_stats']['std_uniformity'] = float(std_uniformity)
            
            if std_uniformity < 0.1:
                characteristics['scaling_quality'] = 'excellent'
            elif std_uniformity < 0.5:
                characteristics['scaling_quality'] = 'good'
            else:
                characteristics['scaling_quality'] = 'poor'
                logger.warning(f"  Feature scales vary significantly (std uniformity: {std_uniformity:.3f})")
            
            # Sample norms
            sample_norms = np.linalg.norm(X, axis=1)
            characteristics['sample_norms'] = {
                'min': float(np.min(sample_norms)),
                'max': float(np.max(sample_norms)),
                'mean': float(np.mean(sample_norms)),
                'std': float(np.std(sample_norms))
            }
            
            return characteristics
        
        def recommend_clustering_algorithm(distance_stats, data_characteristics, params=None):
            #Generate algorithm recommendations based on data properties.
            #All thresholds are configurable via the params dict (from validation_params JSON).
            logger.info("Generating clustering algorithm recommendations")
            
            if params is None:
                params = {}
            
            recommendations = []
            
            mean_dist = distance_stats['distance_stats']['mean']
            std_dist = distance_stats['distance_stats']['std']
            cv_dist = std_dist / (mean_dist + 1e-10)
            
            n_samples = data_characteristics['n_samples']
            n_features = data_characteristics['n_features']
            
            # Configurable thresholds (all have sensible defaults)
            dbscan_cv_threshold = params.get('dbscan_cv_threshold', 0.5)
            hierarchical_small_n = params.get('hierarchical_small_n', 5000)
            hierarchical_med_n = params.get('hierarchical_med_n', 10000)
            high_dim_threshold = params.get('high_dim_threshold', 50)
            
            # KMeans recommendation
            if data_characteristics['scaling_quality'] in ['excellent', 'good']:
                recommendations.append({
                    'algorithm': 'KMeans',
                    'suitability': 'high',
                    'reason': 'Data is well-scaled, good for distance-based clustering'
                })
            
            # DBSCAN recommendation
            if cv_dist > dbscan_cv_threshold and distance_stats.get('pct_zero_distances', 0) < 1:
                recommendations.append({
                    'algorithm': 'DBSCAN',
                    'suitability': 'high',
                    'reason': 'Variable distance distribution suitable for density-based clustering'
                })
            
            # Hierarchical recommendation based on sample size
            if n_samples < hierarchical_small_n:
                recommendations.append({
                    'algorithm': 'AgglomerativeClustering',
                    'suitability': 'high',
                    'reason': 'Sample size appropriate for hierarchical clustering'
                })
            elif n_samples < hierarchical_med_n:
                recommendations.append({
                    'algorithm': 'AgglomerativeClustering',
                    'suitability': 'medium',
                    'reason': 'Sample size at upper limit for hierarchical clustering'
                })
            
            # Spectral recommendation for high dimensions
            if n_features > high_dim_threshold:
                recommendations.append({
                    'algorithm': 'SpectralClustering',
                    'suitability': 'medium',
                    'reason': 'High dimensionality may benefit from spectral methods'
                })
            
            return recommendations
        
        def main():
            parser = argparse.ArgumentParser(
                description="Distance Matrix Validation Component (PARQUET OPTIMIZED)"
            )
            parser.add_argument("--train_data", required=True)
            parser.add_argument("--test_data", default='')
            parser.add_argument("--validation_params", default='{}')
            parser.add_argument("--output_validation_report", required=True)
            parser.add_argument("--output_distance_statistics", required=True)
            
            args = parser.parse_args()
            
            logger.info("="*80)
            logger.info("DISTANCE MATRIX VALIDATION (PARQUET OPTIMIZED)")
            logger.info("="*80)
            logger.info("")
            
            try:
                ensure_directory_exists(args.output_validation_report)
                ensure_directory_exists(args.output_distance_statistics)
                
                params = json.loads(args.validation_params)
                
                # Load data
                train_df = load_data(args.train_data)
                test_df = load_data(args.test_data) if args.test_data else None
                
                if train_df is None or train_df.empty:
                    logger.error("ERROR: Training data is empty")
                    sys.exit(1)
                
                # Get numeric columns
                numeric_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()
                logger.info(f"Analyzing {len(numeric_cols)} numeric features")
                logger.info("")
                
                X_train = train_df[numeric_cols].values
                
                # Get validation parameters
                sample_size = params.get('sample_size', 1000)
                distance_metrics = params.get('distance_metrics', ['euclidean', 'manhattan', 'cosine'])
                
                # Analyze data characteristics
                data_characteristics = analyze_data_characteristics(X_train)
                
                # Validate distance matrices for each metric
                distance_validations = {}
                all_distance_stats = {}
                
                for metric in distance_metrics:
                    logger.info("")
                    logger.info(f"Validating metric: {metric}")
                    logger.info("-" * 80)
                    
                    validation_result, distances = validate_distance_matrix(
                        X_train,
                        metric=metric,
                        sample_size=sample_size,
                        params=params
                    )
                    
                    distance_validations[metric] = validation_result
                    
                    if distances is not None:
                        all_distance_stats[metric] = {
                            'distribution': {
                                'min': float(np.min(distances)),
                                'max': float(np.max(distances)),
                                'mean': float(np.mean(distances)),
                                'median': float(np.median(distances)),
                                'std': float(np.std(distances)),
                                'percentiles': {
                                    '10': float(np.percentile(distances, 10)),
                                    '25': float(np.percentile(distances, 25)),
                                    '50': float(np.percentile(distances, 50)),
                                    '75': float(np.percentile(distances, 75)),
                                    '90': float(np.percentile(distances, 90))
                                }
                            }
                        }
                
                # Compare train and test distributions if test data provided
                if test_df is not None and not test_df.empty:
                    logger.info("")
                    logger.info("Comparing train and test distance distributions")
                    X_test = test_df[numeric_cols].values
                    
                    train_test_comparison = {}
                    
                    for metric in distance_metrics[:1]:  # Just first metric for efficiency
                        train_dists = pdist(X_train[:min(500, len(X_train))], metric=metric)
                        test_dists = pdist(X_test[:min(500, len(X_test))], metric=metric)
                        
                        ks_stat, ks_pval = ks_2samp(train_dists, test_dists)
                        
                        train_test_comparison[metric] = {
                            'ks_statistic': float(ks_stat),
                            'ks_pvalue': float(ks_pval),
                            'distributions_similar': bool(ks_pval > 0.05)
                        }
                        
                        if ks_pval > 0.05:
                            logger.info(f"  oe" {metric}: Train and test distributions are similar (p={ks_pval:.4f})")
                        else:
                            logger.warning(f"  s  {metric}: Train and test distributions differ (p={ks_pval:.4f})")
                    
                    data_characteristics['train_test_comparison'] = train_test_comparison
                
                # Generate recommendations
                recommendations = recommend_clustering_algorithm(
                    distance_validations['euclidean'],
                    data_characteristics,
                    params=params
                )
                
                # Create validation report
                validation_report = {
                    'timestamp': pd.Timestamp.now().isoformat(),
                    'data_characteristics': data_characteristics,
                    'distance_validations': distance_validations,
                    'algorithm_distance_preferences': ALGORITHM_DISTANCE_PREFERENCES,
                    'recommendations': recommendations,
                    'validation_params': params
                }
                
                # Save reports
                with open(args.output_validation_report, 'w') as f:
                    json.dump(validation_report, f, indent=2)
                logger.info("")
                logger.info(f"oe" Validation report saved: {args.output_validation_report}")
                
                with open(args.output_distance_statistics, 'w') as f:
                    json.dump(all_distance_stats, f, indent=2)
                logger.info(f"oe" Distance statistics saved: {args.output_distance_statistics}")
                
                logger.info("")
                logger.info("="*80)
                logger.info("VALIDATION COMPLETED")
                logger.info("="*80)
                logger.info(f"Scaling quality: {data_characteristics['scaling_quality']}")
                logger.info(f"Recommended algorithms: {[r['algorithm'] for r in recommendations if r['suitability'] == 'high']}")
                logger.info("="*80)
                
            except Exception as e:
                logger.error(f"ERROR: {str(e)}")
                import traceback
                traceback.print_exc()
                sys.exit(1)
        
        if __name__ == "__main__":
            main()
    args:
      - --train_data
      - {inputPath: train_data}
      - --test_data
      - {inputPath: test_data}
      - --validation_params
      - {inputValue: validation_params}
      - --output_validation_report
      - {outputPath: validation_report}
      - --output_distance_statistics
      - {outputPath: distance_statistics}
