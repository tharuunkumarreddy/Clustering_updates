name: Distance Matrix Validation Component - PARQUET OPTIMIZED
description: Validates distance matrix properties for clustering algorithms. Checks distance distribution, symmetry, triangle inequality, and provides recommendations for optimal distance metrics and clustering algorithms based on data characteristics. Loads Parquet/CSV.

inputs:
  - name: train_data
    type: Data
    description: 'Preprocessed training dataset (Parquet or CSV)'
  - name: test_data
    type: Data
    description: 'Preprocessed test dataset (Parquet or CSV, optional)'
  - name: validation_params
    type: String
    description: 'Validation parameters as JSON. Examples: {"sample_size":1000}, {"distance_metrics":["euclidean","manhattan"]}'
    default: '{}'

outputs:
  - name: validation_report
    type: Data
    description: 'Distance matrix validation report with recommendations (JSON)'
  - name: distance_statistics
    type: Data
    description: 'Distance distribution statistics (JSON)'

implementation:
  container:
    image: nikhilv215/nesy-factory:v23
    command:
      - python3
      - -u
      - -c
      - |
        import os
        import sys
        import json
        import argparse
        import logging
        import pandas as pd
        import numpy as np
        from scipy.spatial.distance import pdist, squareform, cdist
        from scipy.stats import ks_2samp
        from sklearn.metrics import pairwise_distances
        from pathlib import Path
        
        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
        logger = logging.getLogger('distance_validation')

        # Algorithm-Distance Metric Compatibility Database (PRESERVED IN FULL)
        ALGORITHM_DISTANCE_PREFERENCES = {
            # Centroid-Based
            'KMeans': {
                'recommended': ['euclidean', 'minkowski'],
                'avoid': ['cosine'],
                'reason': 'KMeans uses Euclidean distance for centroid calculation and convergence.'
            },
            'MiniBatchKMeans': {
                'recommended': ['euclidean', 'minkowski'],
                'avoid': ['cosine'],
                'reason': 'Same as KMeans - Euclidean distance for efficient batch processing.'
            },
            'BisectingKMeans': {
                'recommended': ['euclidean', 'minkowski'],
                'avoid': ['cosine'],
                'reason': 'Hierarchical K-means using Euclidean distance for splits.'
            },
            'KMedoids': {
                'recommended': ['euclidean', 'manhattan', 'cosine'],
                'avoid': [],
                'reason': 'K-medoids works with any distance metric - very flexible.'
            },
            
            # Density-Based
            'DBSCAN': {
                'recommended': ['euclidean', 'manhattan', 'chebyshev'],
                'avoid': ['cosine'],
                'reason': 'DBSCAN needs metric space properties for epsilon-neighborhood density calculation.'
            },
            'OPTICS': {
                'recommended': ['euclidean', 'manhattan'],
                'avoid': ['cosine'],
                'reason': 'OPTICS requires metric space for reachability distance computation.'
            },
            'HDBSCAN': {
                'recommended': ['euclidean', 'manhattan'],
                'avoid': ['cosine'],
                'reason': 'Hierarchical density clustering needs metric space for mutual reachability.'
            },
            
            # Hierarchical
            'AgglomerativeClustering': {
                'recommended': ['euclidean', 'manhattan', 'cosine', 'correlation'],
                'avoid': [],
                'reason': 'Hierarchical clustering works with any distance metric based on linkage.'
            },
            'BIRCH': {
                'recommended': ['euclidean'],
                'avoid': ['manhattan', 'cosine'],
                'reason': 'BIRCH uses Euclidean distance for clustering feature tree construction.'
            },
            
            # Distribution-Based
            'GaussianMixture': {
                'recommended': ['euclidean'],
                'avoid': [],
                'reason': 'GMM uses Mahalanobis distance internally for Gaussian likelihood.'
            },
            'BayesianGaussianMixture': {
                'recommended': ['euclidean'],
                'avoid': [],
                'reason': 'Bayesian GMM uses probabilistic distances based on Gaussian assumptions.'
            },
            
            # Fuzzy
            'FuzzyCMeans': {
                'recommended': ['euclidean', 'manhattan'],
                'avoid': [],
                'reason': 'Fuzzy C-Means uses distance for membership degree calculation.'
            },
            
            # Other
            'MeanShift': {
                'recommended': ['euclidean'],
                'avoid': ['manhattan', 'cosine'],
                'reason': 'Mean Shift uses Euclidean distance for kernel density estimation.'
            },
            'AffinityPropagation': {
                'recommended': ['euclidean', 'manhattan'],
                'avoid': [],
                'reason': 'Affinity Propagation uses negative squared distance for similarity matrix.'
            },
            'SpectralClustering': {
                'recommended': ['rbf', 'euclidean'],
                'avoid': ['manhattan', 'chebyshev'],
                'reason': 'Spectral uses RBF kernel or Euclidean for similarity/affinity matrix.'
            }
        }
        
        def ensure_directory_exists(file_path):
            #Ensure directory exists for output file#
            directory = os.path.dirname(file_path)
            if directory:
                os.makedirs(directory, exist_ok=True)
        
        def load_data(input_path):
            #Load data from Parquet or CSV#
            if not input_path or input_path == '':
                return None
            
            logger.info(f"Loading dataset from: {input_path}")
            ext = Path(input_path).suffix.lower()
            
            if ext in ['.parquet', '.pq']:
                df = pd.read_parquet(input_path, engine='pyarrow')
                logger.info("✓ Loaded Parquet file")
            else:
                df = pd.read_csv(input_path)
                logger.info("✓ Loaded CSV file")
            
            logger.info(f"Shape: {df.shape[0]} rows x {df.shape[1]} columns")
            return df
        
        def validate_distance_matrix(X, metric='euclidean', sample_size=None):
            #Validate distance matrix properties
            #Checks: symmetry, triangle inequality, zero diagonal, distance distribution
            logger.info("Validating distance matrix properties")
            logger.info(f"  Metric: {metric}")
            logger.info(f"  Data shape: {X.shape}")
            
            # Sample if needed
            if sample_size and len(X) > sample_size:
                logger.info(f"  Sampling {sample_size} points for validation")
                indices = np.random.choice(len(X), sample_size, replace=False)
                X_sample = X[indices]
            else:
                X_sample = X
            
            validation_results = {
                'metric': metric,
                'n_samples': len(X_sample),
                'n_features': X.shape[1]
            }
            
            try:
                # Compute pairwise distances
                distances = pdist(X_sample, metric=metric)
                dist_matrix = squareform(distances)
                
                validation_results['distance_computed'] = True
                
                # Distance statistics
                validation_results['distance_stats'] = {
                    'min': float(np.min(distances)),
                    'max': float(np.max(distances)),
                    'mean': float(np.mean(distances)),
                    'median': float(np.median(distances)),
                    'std': float(np.std(distances)),
                    'q25': float(np.percentile(distances, 25)),
                    'q75': float(np.percentile(distances, 75))
                }
                
                logger.info(f"  Distance range: {validation_results['distance_stats']['min']:.4f} " +
                           f"to {validation_results['distance_stats']['max']:.4f}")
                logger.info(f"  Distance mean: {validation_results['distance_stats']['mean']:.4f}")
                
                # Check symmetry
                is_symmetric = np.allclose(dist_matrix, dist_matrix.T)
                validation_results['is_symmetric'] = bool(is_symmetric)
                
                # Check diagonal is zero
                diagonal_zero = np.allclose(np.diag(dist_matrix), 0)
                validation_results['diagonal_is_zero'] = bool(diagonal_zero)
                
                # Check triangle inequality (only for small samples)
                if len(X_sample) <= 100:
                    triangle_violations = 0
                    for i in range(len(dist_matrix)):
                        for j in range(i+1, len(dist_matrix)):
                            for k in range(j+1, len(dist_matrix)):
                                if dist_matrix[i,j] > dist_matrix[i,k] + dist_matrix[k,j] + 1e-10:
                                    triangle_violations += 1
                    
                    validation_results['triangle_inequality_violations'] = int(triangle_violations)
                    validation_results['triangle_inequality_satisfied'] = bool(triangle_violations == 0)
                    logger.info(f"  Triangle inequality violations: {triangle_violations}")
                else:
                    validation_results['triangle_inequality_check'] = 'skipped (too many samples)'
                
                # Check for zero distances (duplicates)
                zero_distances = np.sum(distances == 0)
                validation_results['n_zero_distances'] = int(zero_distances)
                validation_results['pct_zero_distances'] = float(zero_distances / len(distances) * 100)
                
                if validation_results['pct_zero_distances'] > 5:
                    logger.warning(f"  ⚠ Warning: {validation_results['pct_zero_distances']:.2f}% " +
                                 f"of distances are zero (possible duplicates)")
                
                # Nearest neighbor statistics
                nearest_neighbor_dists = np.partition(
                    dist_matrix + np.eye(len(dist_matrix))*1e10, 1, axis=1
                )[:,1]
                validation_results['nearest_neighbor_stats'] = {
                    'min': float(np.min(nearest_neighbor_dists)),
                    'max': float(np.max(nearest_neighbor_dists)),
                    'mean': float(np.mean(nearest_neighbor_dists)),
                    'median': float(np.median(nearest_neighbor_dists))
                }
                
                logger.info(f"  Nearest neighbor distance (mean): " +
                           f"{validation_results['nearest_neighbor_stats']['mean']:.4f}")
                
            except Exception as e:
                logger.error(f"  Failed to compute distance matrix: {str(e)}")
                validation_results['distance_computed'] = False
                validation_results['error'] = str(e)
            
            return validation_results, distances if 'distances' in locals() else None
        
        def analyze_data_characteristics(X):
            #Analyze data characteristics for algorithm recommendations#
            logger.info("Analyzing data characteristics")
            
            characteristics = {
                'n_samples': X.shape[0],
                'n_features': X.shape[1],
                'feature_stats': {}
            }
            
            # Feature scale analysis
            feature_means = np.mean(X, axis=0)
            feature_stds = np.std(X, axis=0)
            
            characteristics['feature_stats']['mean_range'] = [
                float(np.min(feature_means)), 
                float(np.max(feature_means))
            ]
            characteristics['feature_stats']['std_range'] = [
                float(np.min(feature_stds)), 
                float(np.max(feature_stds))
            ]
            
            # Check scaling uniformity
            std_uniformity = np.std(feature_stds) / (np.mean(feature_stds) + 1e-10)
            characteristics['feature_stats']['std_uniformity'] = float(std_uniformity)
            
            if std_uniformity < 0.1:
                characteristics['scaling_quality'] = 'excellent'
            elif std_uniformity < 0.5:
                characteristics['scaling_quality'] = 'good'
            else:
                characteristics['scaling_quality'] = 'poor'
                logger.warning(f"  Feature scales vary significantly (std uniformity: {std_uniformity:.3f})")
            
            # Sample norms
            sample_norms = np.linalg.norm(X, axis=1)
            characteristics['sample_norms'] = {
                'min': float(np.min(sample_norms)),
                'max': float(np.max(sample_norms)),
                'mean': float(np.mean(sample_norms)),
                'std': float(np.std(sample_norms))
            }
            
            return characteristics
        
        def recommend_clustering_algorithm(distance_stats, data_characteristics):
            #Generate algorithm recommendations based on data properties#
            logger.info("Generating clustering algorithm recommendations")
            
            recommendations = []
            
            mean_dist = distance_stats['distance_stats']['mean']
            std_dist = distance_stats['distance_stats']['std']
            cv_dist = std_dist / (mean_dist + 1e-10)
            
            n_samples = data_characteristics['n_samples']
            n_features = data_characteristics['n_features']
            
            # KMeans recommendation
            if data_characteristics['scaling_quality'] in ['excellent', 'good']:
                recommendations.append({
                    'algorithm': 'KMeans',
                    'suitability': 'high',
                    'reason': 'Data is well-scaled, good for distance-based clustering'
                })
            
            # DBSCAN recommendation
            if cv_dist > 0.5 and distance_stats.get('pct_zero_distances', 0) < 1:
                recommendations.append({
                    'algorithm': 'DBSCAN',
                    'suitability': 'high',
                    'reason': 'Variable distance distribution suitable for density-based clustering'
                })
            
            # Hierarchical recommendation based on sample size
            if n_samples < 5000:
                recommendations.append({
                    'algorithm': 'AgglomerativeClustering',
                    'suitability': 'high',
                    'reason': 'Sample size appropriate for hierarchical clustering'
                })
            elif n_samples < 10000:
                recommendations.append({
                    'algorithm': 'AgglomerativeClustering',
                    'suitability': 'medium',
                    'reason': 'Sample size at upper limit for hierarchical clustering'
                })
            
            # Spectral recommendation for high dimensions
            if n_features > 50:
                recommendations.append({
                    'algorithm': 'SpectralClustering',
                    'suitability': 'medium',
                    'reason': 'High dimensionality may benefit from spectral methods'
                })
            
            return recommendations
        
        def main():
            parser = argparse.ArgumentParser(
                description="Distance Matrix Validation Component (PARQUET OPTIMIZED)"
            )
            parser.add_argument("--train_data", required=True)
            parser.add_argument("--test_data", default='')
            parser.add_argument("--validation_params", default='{}')
            parser.add_argument("--output_validation_report", required=True)
            parser.add_argument("--output_distance_statistics", required=True)
            
            args = parser.parse_args()
            
            logger.info("="*80)
            logger.info("DISTANCE MATRIX VALIDATION (PARQUET OPTIMIZED)")
            logger.info("="*80)
            logger.info("")
            
            try:
                ensure_directory_exists(args.output_validation_report)
                ensure_directory_exists(args.output_distance_statistics)
                
                params = json.loads(args.validation_params)
                
                # Load data
                train_df = load_data(args.train_data)
                test_df = load_data(args.test_data) if args.test_data else None
                
                if train_df is None or train_df.empty:
                    logger.error("ERROR: Training data is empty")
                    sys.exit(1)
                
                # Get numeric columns
                numeric_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()
                logger.info(f"Analyzing {len(numeric_cols)} numeric features")
                logger.info("")
                
                X_train = train_df[numeric_cols].values
                
                # Get validation parameters
                sample_size = params.get('sample_size', 1000)
                distance_metrics = params.get('distance_metrics', ['euclidean', 'manhattan', 'cosine'])
                
                # Analyze data characteristics
                data_characteristics = analyze_data_characteristics(X_train)
                
                # Validate distance matrices for each metric
                distance_validations = {}
                all_distance_stats = {}
                
                for metric in distance_metrics:
                    logger.info("")
                    logger.info(f"Validating metric: {metric}")
                    logger.info("-" * 80)
                    
                    validation_result, distances = validate_distance_matrix(
                        X_train,
                        metric=metric,
                        sample_size=sample_size
                    )
                    
                    distance_validations[metric] = validation_result
                    
                    if distances is not None:
                        all_distance_stats[metric] = {
                            'distribution': {
                                'min': float(np.min(distances)),
                                'max': float(np.max(distances)),
                                'mean': float(np.mean(distances)),
                                'median': float(np.median(distances)),
                                'std': float(np.std(distances)),
                                'percentiles': {
                                    '10': float(np.percentile(distances, 10)),
                                    '25': float(np.percentile(distances, 25)),
                                    '50': float(np.percentile(distances, 50)),
                                    '75': float(np.percentile(distances, 75)),
                                    '90': float(np.percentile(distances, 90))
                                }
                            }
                        }
                
                # Compare train and test distributions if test data provided
                if test_df is not None and not test_df.empty:
                    logger.info("")
                    logger.info("Comparing train and test distance distributions")
                    X_test = test_df[numeric_cols].values
                    
                    train_test_comparison = {}
                    
                    for metric in distance_metrics[:1]:  # Just first metric for efficiency
                        train_dists = pdist(X_train[:min(500, len(X_train))], metric=metric)
                        test_dists = pdist(X_test[:min(500, len(X_test))], metric=metric)
                        
                        ks_stat, ks_pval = ks_2samp(train_dists, test_dists)
                        
                        train_test_comparison[metric] = {
                            'ks_statistic': float(ks_stat),
                            'ks_pvalue': float(ks_pval),
                            'distributions_similar': bool(ks_pval > 0.05)
                        }
                        
                        if ks_pval > 0.05:
                            logger.info(f"  ✓ {metric}: Train and test distributions are similar (p={ks_pval:.4f})")
                        else:
                            logger.warning(f"  ⚠ {metric}: Train and test distributions differ (p={ks_pval:.4f})")
                    
                    data_characteristics['train_test_comparison'] = train_test_comparison
                
                # Generate recommendations
                recommendations = recommend_clustering_algorithm(
                    distance_validations['euclidean'],
                    data_characteristics
                )
                
                # Create validation report
                validation_report = {
                    'timestamp': pd.Timestamp.now().isoformat(),
                    'data_characteristics': data_characteristics,
                    'distance_validations': distance_validations,
                    'algorithm_distance_preferences': ALGORITHM_DISTANCE_PREFERENCES,
                    'recommendations': recommendations,
                    'validation_params': params
                }
                
                # Save reports
                with open(args.output_validation_report, 'w') as f:
                    json.dump(validation_report, f, indent=2)
                logger.info("")
                logger.info(f"✓ Validation report saved: {args.output_validation_report}")
                
                with open(args.output_distance_statistics, 'w') as f:
                    json.dump(all_distance_stats, f, indent=2)
                logger.info(f"✓ Distance statistics saved: {args.output_distance_statistics}")
                
                logger.info("")
                logger.info("="*80)
                logger.info("VALIDATION COMPLETED")
                logger.info("="*80)
                logger.info(f"Scaling quality: {data_characteristics['scaling_quality']}")
                logger.info(f"Recommended algorithms: {[r['algorithm'] for r in recommendations if r['suitability'] == 'high']}")
                logger.info("="*80)
                
            except Exception as e:
                logger.error(f"ERROR: {str(e)}")
                import traceback
                traceback.print_exc()
                sys.exit(1)
        
        if __name__ == "__main__":
            main()
    args:
      - --train_data
      - {inputPath: train_data}
      - --test_data
      - {inputPath: test_data}
      - --validation_params
      - {inputValue: validation_params}
      - --output_validation_report
      - {outputPath: validation_report}
      - --output_distance_statistics
      - {outputPath: distance_statistics}
